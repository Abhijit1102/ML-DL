{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2386f95a",
   "metadata": {},
   "source": [
    "## CNN\n",
    "**CNN is widly used in Image processing**\n",
    "CNN's are a special neural networks for processing data has agris like topology such as time series(1D) or image(2D).\n",
    "\n",
    "- In CNN thier is convolution layer which perform operation called convolution which is different from ANN other than matrix multiplication.\n",
    "- layers in CNN\n",
    "      - 1st layer: convolution layer\n",
    "      - 2nd layer: pooling layer\n",
    "      - 3rd layer: fully connected layer\n",
    "\n",
    "**Inspire by vistual cortex of Humans**\n",
    "used:\n",
    "- facial recogniation\n",
    "- car driving\n",
    "- Hand writing recognation\n",
    "\n",
    "**Advatage of CNN over ANN**\n",
    "\n",
    "Reason:\n",
    " - High Computation Cost\n",
    " - Overfitting\n",
    " - loss of imp info like special arrangement of pixels.\n",
    " \n",
    "**ANN convert pixel-image into 1D input resulting increase of parameter, overfitting due to unwanted availabilty of unwanted pixel, loss infomnation between topology of pixels(special arrangements of pixels)** \n",
    "\n",
    "**While CNN try to extract premitive features**\n",
    "**At begganing Convolution layers each premitive feature are extracted**\n",
    "**Then each primitive feature are convoluted to form complex feature**\n",
    "**This complex features extracted to form complex features again layer after layer untill main features are extracted**\n",
    "      \n",
    "## Convolution operation is denoted by \"*\"  which is filter   \n",
    "<img src=\"https://i0.wp.com/developersbreach.com/wp-content/uploads/2020/08/cnn_banner.png?fit=1400%2C658&ssl=1\">  \n",
    "\n",
    "**Task used by CNN**\n",
    "- Image classffication\n",
    "- Object locatization\n",
    "- Object detection\n",
    "- face detection and face recognition\n",
    "- image pegmentation(dividing the image into segment)\n",
    "- black and white to color\n",
    "- positute detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa6c76b",
   "metadata": {},
   "source": [
    "## Motivation of CNN\n",
    "\n",
    "- Human Vistual Cortex : light passes to retina lika 2d sheet this info transfer(as electro-chemical impluse) by optical nerve to thalamus where preprocessing happens, and axions transfer it into V1(Vistual cortex)\n",
    "\n",
    "**Hubel and Wiesel experiment**\n",
    "Hubel and Wiesel demonstrated that some neurons were only responsive to information that came from a single eye, a phenomenon they referred to as “ocular dominance”. Intriguingly, neurons that are tuned to a particular eye cluster together in anatomical columns in the visual cortex of the brain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "add11262",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\display.py:431: UserWarning: Consider using IPython.display.IFrame instead\n",
      "  warnings.warn(\"Consider using IPython.display.IFrame instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IOHayh06LJ4\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IOHayh06LJ4\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc6b957",
   "metadata": {},
   "source": [
    "<img src=\"https://www.informit.com/content/images/chap7_9780137055098/elementLinks/th07bra04.jpg\">\n",
    "\n",
    "Conclusion:\n",
    "- Two simple cell: simple cell and complex cell\n",
    "      - simple cell: Its called orientation cell or feature detechtor cell, they are smaller receptive field like edge detection.\n",
    "      - complex cell: they are bigger receptive field which is process by simple cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eb41fe",
   "metadata": {},
   "source": [
    "## Vertical Edge Detection IN CNN\n",
    "<img src=\"https://kharshit.github.io/img/edge_detection.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f5b8db",
   "metadata": {},
   "source": [
    "# RGB filter in CNN\n",
    "<img src=\"https://media5.datahacker.rs/2018/11/06_04-1024x343.png\">\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/9/95/Convolutional_Neural_Network_with_Color_Image_Filter.gif\">\n",
    "\n",
    "- (m x m x c) * (n x n x c) = (m - n +1) (m - n + 1)\n",
    "\n",
    "## Problem with CNN\n",
    "- Loss of information\n",
    "- less participation of edge pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1708d844",
   "metadata": {},
   "source": [
    "# Padding in CNN\n",
    "- Padding is simply a process of adding layers of zeros to our input images so as to avoid the problems mentioned above. This prevents shrinking as, if p = number of layers of zeros added to the border of the image, then our (n x n) image becomes (n + 2p) x (n + 2p) image after padding.\n",
    "\n",
    "- In padding we increase the both row and columns pixels\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/786/1*O06nY1U7zoP4vE5AZEnxKA.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439a9709",
   "metadata": {},
   "source": [
    "# Padding in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72943d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D\n",
    "from keras import Sequential\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf23889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21d065e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='valid', activation='relu'))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='valid', activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "568b9613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 32)        9248      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 15488)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1982592   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,002,698\n",
      "Trainable params: 2,002,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2dc6b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using padding\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='same', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='same', activation='relu'))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='same', activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8d5ce0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 28, 28, 32)        9248      \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               3211392   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,231,498\n",
      "Trainable params: 3,231,498\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e07fce7",
   "metadata": {},
   "source": [
    "# Strides\n",
    "- Stride is a component of convolutional neural networks, or neural networks tuned for the compression of images and video data. Stride is a parameter of the neural network's filter that modifies the amount of movement over the image or video\n",
    "\n",
    "<img src=\"https://programmathically.com/wp-content/uploads/2021/12/Screenshot-2021-12-03-at-09.46.05.png\">\n",
    "\n",
    "$$ \\frac{n+2p -f}{2} +1 $$\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/0/04/Convolution_arithmetic_-_Padding_strides.gif?20190413174630\">\n",
    "\n",
    "**Why strided are required**\n",
    "- High level features\n",
    "- Computing power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d44c67d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='valid', activation='relu'))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='valid', activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "773e307d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 22, 22, 32)        9248      \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 15488)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               1982592   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,002,698\n",
      "Trainable params: 2,002,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4931536f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# striding\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='same',strides=(2,2), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='same',strides=(2,2), activation='relu'))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='same',strides=(2,2), activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4a68e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 7, 7, 32)          9248      \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 4, 4, 32)          9248      \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,770\n",
      "Trainable params: 85,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4e3db3",
   "metadata": {},
   "source": [
    "## Pooling layers in CNN\n",
    "The pooling operation involves sliding a two-dimensional filter over each channel of the feature map and summarising the features lying within the region covered by the filter.\n",
    "\n",
    "The pooling operation involves sliding a two-dimensional filter over each channel of the feature map and summarising the features lying within the region covered by the filter.\n",
    "\n",
    "**Problem with CNN is memmory and translation variable**\n",
    "\n",
    "**input of CNN(228x228x3)->filter(100)->featrue_map(226x226)x100x32=19MD**\n",
    "\n",
    "**Translation variance: In CNN location of featurers is detected but we want Translation Invariants**\n",
    "\n",
    "<img src=\"https://i.stack.imgur.com/iY5n5.png\">\n",
    "\n",
    " Pooling layers are used to reduce the dimensions of the feature maps. Thus, it reduces the number of parameters to learn and the amount of computation performed in the network. The pooling layer summarises the features present in a region of the feature map generated by a convolution layer\n",
    "\n",
    "<img src=\"https://developers.google.com/static/machine-learning/practica/image-classification/images/maxpool_animation.gif\">\n",
    "\n",
    "- in pooling provide size=(2,2) -> stride=2 -> type -> max \n",
    "\n",
    "- 1st_ly convulation are converted into non linear feature map -> pooling_map\n",
    "\n",
    "vis: https://deeplizard.com/resource/pavq7noze3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b0f347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
    "model.add(Conv2D(32,kernel_size=(3,3),padding='valid', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c90d9ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_14 (Conv2D)          (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 11, 11, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               102528    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113,386\n",
      "Trainable params: 113,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d86d0e",
   "metadata": {},
   "source": [
    "## Advantages of pooling\n",
    "- Reduce size\n",
    "- Translation in variance due to down sampling\n",
    "- Enhanced feature(intensiting of feature increaed) in case of Max pooling done in local reicptive pooling\n",
    "- No need of training\n",
    "\n",
    "type of pooling:\n",
    "- Maxpooling, Min pooling\n",
    "- Average pooling\n",
    "- Global pooling(Global max, Global average) its used in the end(last flattened layer)\n",
    "\n",
    "# Disadvantages\n",
    "- Imagesegmentaion pooling is not used\n",
    "- loss iof information (1/4 information is retained)\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0949b646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d96be4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
