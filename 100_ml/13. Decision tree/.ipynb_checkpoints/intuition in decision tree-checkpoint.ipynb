{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd759421",
   "metadata": {},
   "source": [
    "### Decision tree\n",
    "<p>Decision Tree is the most powerful and popular tool for classification and prediction. A Decision tree is a flowchart-like tree structure, where each internal node denotes a test on an attribute, each branch represents an outcome of the test, and each leaf node (terminal node) holds a class label. </p>\n",
    "<img src=\"https://media.geeksforgeeks.org/wp-content/cdn-uploads/Decision_Tree-2.png\">\n",
    "\n",
    "## Disadvantages\n",
    "- Overfitting\n",
    "- Prone to error for imbalance datasets\n",
    "\n",
    "## Entropy\n",
    "- Entropy is nothing but the measure of disorder. Its also used in computer science as ap part of missing theory.\n",
    "- In information theory, the entropy of a random variable is the average level of \"information\", \"surprise\", or \"uncertainty\" inherent to the variable's possible outcomes. \n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/5a9e707eb6c54290db4ee6be05582944e34e30c8\">\n",
    "\n",
    "## observation\n",
    "- More the uncertainity more is entropy\n",
    "- For a 2 class problem the min entropy is 0 and the max is 1\n",
    "<img src=\"https://miro.medium.com/max/640/1*M15RZMSk8nGEyOnD8haF-A.webp\">\n",
    "\n",
    "# Entropy in continuous variable\n",
    "- Higher peak value of kde higher is entropy and viz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8b8443",
   "metadata": {},
   "source": [
    "# Information Gain\n",
    "- Information gain is metric used to train decision trees, Specailly,this metric measure the quality of split.\n",
    "- The information gain is baised on the decrease in entropy after a data set on an attribute that returns the highest information.\n",
    "- Inforrmation gain = E(parent) + wieght_average*E(childern)\n",
    "- if entropy is zero i.e once a leaf node is reached."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6f1ca6e",
   "metadata": {},
   "source": [
    "## Decesion trees (gini impurity)\n",
    "- It measure purity of nodes\n",
    "<img src=\"https://static.wixstatic.com/media/02b811_5df05513ffd4487d843bb401dfa5e0cb~mv2.png\">\n",
    "- when to used py=0.5(yes), py=0.5(No): E=1(max), G=0.5(max=0.5). gini is computationlly first but Entropy will give up more balance tree whearas gini is overfitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbeb241",
   "metadata": {},
   "source": [
    "### How to handle numerical data in decesion tree\n",
    "- if num_col > n: spliting it into data set\n",
    "- D -> f >v1 -> D1, D2 -> E1, E2 -> WE1 ->IG\n",
    "- N information gain Max{ IG's}\n",
    "\n",
    "### decission trees are faster in columns having catagorical \n",
    "\n",
    "### Its has issue of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2978848",
   "metadata": {},
   "source": [
    "### Depth of tree (overfitting vs underfitting)\n",
    "<img src=\"https://www.jcchouinard.com/wp-content/uploads/2021/11/image-1-1024x929.png.webp\">\n",
    "\n",
    "- what if last node is noisy i.e. thier will be issue of overfitting. in sklearn:depth_max= none is default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1f7a95",
   "metadata": {},
   "source": [
    "### Parameter\n",
    "- Criteria: gini, Entropy\n",
    "- Slipter: for numerical columns : at random, best defaut\n",
    "- Max depth: (overfitting)none, max depth =1(under-fitting)\n",
    "- Min sample split: can controll when to split dependin on number of rows. (with  increrase of this paramter changes of under fitting increase and viz.)\n",
    "- Min sample leaf: no of split at leaf at no os rows(with increase overfitting)\n",
    "- Max featues: No of split with depending on columns at random ( with increase overfitting)\n",
    "- Max leaf node: no of node with aloriyh will run\n",
    "- mean impurity decrease : split depending with information gain criteria\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb236ac3",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ddb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
